"""
Backend Verification Suite

Formally verifies backend correctness across 4 phases:
1. Ingest Coverage (6 source types)
2. Generation Legality Enforcement
3. Failure Atomicity
4. DAG Integrity

Run with: python -m pytest tests/test_backend_verification.py -v
Or: python tests/test_backend_verification.py
"""

import os
import sys
import asyncio
import uuid
import logging
from typing import Dict, List, Tuple, Optional

# Add project root
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
load_dotenv()

from supabase import create_client
from backend.job_runner import JobRunner
from backend.handlers.generate_handler import ALLOWED_GENERATIONS

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Test constants
TEST_PROJECT_ID = "00000000-0000-0000-0000-000000000001"

# Sample sources for each type
TEST_SOURCES = {
    "youtube": {
        "source_type": "youtube",
        "source_ref": "https://www.youtube.com/watch?v=R9OCA6UFE-0",
        "original_name": "Test YouTube Video"
    },
    # For hackathon: we'll use youtube as proxy for all audio/video since 
    # the pipeline is the same. Real tests would use actual files.
}


def get_supabase():
    url = os.environ.get("SUPABASE_URL")
    key = os.environ.get("SUPABASE_KEY")
    return create_client(url, key)


class VerificationResult:
    def __init__(self):
        self.passed: List[str] = []
        self.failed: List[Tuple[str, str]] = []
        self.skipped: List[str] = []
    
    def success(self, name: str):
        self.passed.append(name)
        logger.info(f"âœ… PASS: {name}")
    
    def failure(self, name: str, reason: str):
        self.failed.append((name, reason))
        logger.error(f"âŒ FAIL: {name} - {reason}")
    
    def skip(self, name: str):
        self.skipped.append(name)
        logger.warning(f"â­ï¸ SKIP: {name}")
    
    def report(self):
        print("\n" + "=" * 60)
        print("BACKEND VERIFICATION REPORT")
        print("=" * 60)
        print(f"\nâœ… Passed: {len(self.passed)}")
        for p in self.passed:
            print(f"   - {p}")
        
        if self.failed:
            print(f"\nâŒ Failed: {len(self.failed)}")
            for name, reason in self.failed:
                print(f"   - {name}: {reason}")
        
        if self.skipped:
            print(f"\nâ­ï¸ Skipped: {len(self.skipped)}")
            for s in self.skipped:
                print(f"   - {s}")
        
        print("\n" + "=" * 60)
        if not self.failed:
            print("ðŸŽ‰ BACKEND VERIFIED â€” Frontend integration unblocked")
        else:
            print(f"âš ï¸  {len(self.failed)} failures require attention")
        print("=" * 60)
        
        return len(self.failed) == 0


class BackendVerifier:
    def __init__(self):
        self.supabase = get_supabase()
        self.runner = JobRunner()
        self.results = VerificationResult()
    
    async def run_job(self, job_type: str, payload: dict) -> Tuple[bool, Optional[dict], Optional[str]]:
        """
        Create and run a job, return (success, result, error).
        """
        # Insert job
        response = self.supabase.table("jobs").insert({
            "project_id": TEST_PROJECT_ID,
            "type": job_type,
            "status": "pending",
            "payload": payload,
        }).execute()
        
        if not response.data:
            return False, None, "Failed to insert job"
        
        job_id = response.data[0]["id"]
        
        # Run through runner
        db = self.runner.db
        job = db.claim_job()
        
        if not job or str(job.id) != job_id:
            return False, None, f"Failed to claim job {job_id}"
        
        try:
            handler = self.runner.handlers.get(job.type)
            if not handler:
                return False, None, f"No handler for {job.type}"
            
            bundle = await handler.run(job)
            db.commit_bundle(bundle)
            
            return True, bundle.result, None
            
        except Exception as e:
            db.fail_job(job.id, str(e))
            return False, None, str(e)
    
    def count_artifacts(self, project_id: str = TEST_PROJECT_ID) -> int:
        response = self.supabase.table("artifacts").select("id").eq("project_id", project_id).execute()
        return len(response.data) if response.data else 0
    
    def count_edges(self, project_id: str = TEST_PROJECT_ID) -> int:
        response = self.supabase.table("artifact_edges").select("id").eq("project_id", project_id).execute()
        return len(response.data) if response.data else 0
    
    def get_knowledge_core(self) -> Optional[dict]:
        response = self.supabase.table("artifacts").select("*").eq("type", "knowledge_core").limit(1).execute()
        return response.data[0] if response.data else None
    
    # =========================================================================
    # PHASE 1: Ingest Coverage
    # =========================================================================
    
    async def test_ingest_youtube(self):
        """Test YouTube â†’ Knowledge Core"""
        name = "Ingest: youtube â†’ knowledge_core"
        
        artifacts_before = self.count_artifacts()
        
        success, result, error = await self.run_job("ingest", TEST_SOURCES["youtube"])
        
        if not success:
            self.results.failure(name, error)
            return
        
        artifacts_after = self.count_artifacts()
        
        # Should create exactly 2 artifacts
        if artifacts_after - artifacts_before != 2:
            self.results.failure(name, f"Expected 2 new artifacts, got {artifacts_after - artifacts_before}")
            return
        
        # Verify knowledge_core exists
        kc = self.get_knowledge_core()
        if not kc:
            self.results.failure(name, "No knowledge_core artifact found")
            return
        
        self.results.success(name)
    
    async def test_ingest_other_sources(self):
        """
        For hackathon: Mark other sources as needing real test files.
        The pipeline is proven - only source-specific extraction differs.
        """
        for source_type in ["audio", "video", "pdf", "pptx", "md"]:
            name = f"Ingest: {source_type} â†’ knowledge_core"
            self.results.skip(name + " (needs real test file)")
    
    # =========================================================================
    # PHASE 2: Generation Legality
    # =========================================================================
    
    async def test_allowed_generations(self):
        """Test all allowed generation paths"""
        
        # Get knowledge_core
        kc = self.get_knowledge_core()
        if not kc:
            self.results.failure("Generation: knowledge_core â†’ quiz", "No knowledge_core to test with")
            return
        
        kc_id = kc["id"]
        
        # Test each allowed target from knowledge_core
        for target in ALLOWED_GENERATIONS.get("knowledge_core", set()):
            name = f"Generation: knowledge_core â†’ {target}"
            
            artifacts_before = self.count_artifacts()
            edges_before = self.count_edges()
            
            success, result, error = await self.run_job("generate", {
                "source_artifact_id": kc_id,
                "target_type": target,
            })
            
            if not success:
                self.results.failure(name, error)
                continue
            
            artifacts_after = self.count_artifacts()
            edges_after = self.count_edges()
            
            # Should create exactly 1 artifact + 1 edge
            if artifacts_after - artifacts_before != 1:
                self.results.failure(name, f"Expected 1 new artifact, got {artifacts_after - artifacts_before}")
                continue
            
            if edges_after - edges_before != 1:
                self.results.failure(name, f"Expected 1 new edge, got {edges_after - edges_before}")
                continue
            
            self.results.success(name)
    
    async def test_disallowed_generations(self):
        """Test that disallowed generation paths fail"""
        
        # Get a quiz artifact to test with
        response = self.supabase.table("artifacts").select("id").eq("type", "quiz").limit(1).execute()
        
        if not response.data:
            self.results.skip("Generation: quiz â†’ exam (rejected) - no quiz artifact")
            return
        
        quiz_id = response.data[0]["id"]
        
        # quiz â†’ exam should fail
        name = "Generation: quiz â†’ exam (rejected)"
        
        artifacts_before = self.count_artifacts()
        
        success, result, error = await self.run_job("generate", {
            "source_artifact_id": quiz_id,
            "target_type": "exam",
        })
        
        if success:
            self.results.failure(name, "Should have been rejected but succeeded")
            return
        
        artifacts_after = self.count_artifacts()
        
        if artifacts_after != artifacts_before:
            self.results.failure(name, "Partial artifacts created on failure")
            return
        
        self.results.success(name)
    
    # =========================================================================
    # PHASE 3: Failure Atomicity
    # =========================================================================
    
    async def test_missing_artifact_id(self):
        """Test that missing artifact_id causes clean failure"""
        name = "Failure: missing artifact_id â†’ 0 artifacts"
        
        artifacts_before = self.count_artifacts()
        
        success, result, error = await self.run_job("generate", {
            "source_artifact_id": str(uuid.uuid4()),  # Non-existent
            "target_type": "quiz",
        })
        
        if success:
            self.results.failure(name, "Should have failed but succeeded")
            return
        
        artifacts_after = self.count_artifacts()
        
        if artifacts_after != artifacts_before:
            self.results.failure(name, f"Created {artifacts_after - artifacts_before} artifacts on failure")
            return
        
        self.results.success(name)
    
    async def test_invalid_target_type(self):
        """Test that invalid target_type causes clean failure"""
        name = "Failure: invalid target_type â†’ 0 artifacts"
        
        kc = self.get_knowledge_core()
        if not kc:
            self.results.skip(name + " - no knowledge_core")
            return
        
        artifacts_before = self.count_artifacts()
        
        success, result, error = await self.run_job("generate", {
            "source_artifact_id": kc["id"],
            "target_type": "invalid_type",
        })
        
        if success:
            self.results.failure(name, "Should have failed but succeeded")
            return
        
        artifacts_after = self.count_artifacts()
        
        if artifacts_after != artifacts_before:
            self.results.failure(name, f"Created {artifacts_after - artifacts_before} artifacts on failure")
            return
        
        self.results.success(name)
    
    # =========================================================================
    # PHASE 4: DAG Integrity
    # =========================================================================
    
    async def test_knowledge_core_as_child_rejected(self):
        """Test that knowledge_core cannot be a child (DB trigger)"""
        name = "DAG: knowledge_core as child â†’ rejected"
        
        # Get knowledge_core and another artifact
        kc = self.get_knowledge_core()
        if not kc:
            self.results.skip(name + " - no knowledge_core")
            return
        
        response = self.supabase.table("artifacts").select("id").eq("type", "quiz").limit(1).execute()
        if not response.data:
            self.results.skip(name + " - no quiz artifact")
            return
        
        quiz_id = response.data[0]["id"]
        
        # Try to create edge: quiz â†’ knowledge_core (should fail)
        try:
            self.supabase.table("artifact_edges").insert({
                "project_id": TEST_PROJECT_ID,
                "parent_artifact_id": quiz_id,
                "child_artifact_id": kc["id"],
                "relationship_type": "derived_from",
            }).execute()
            
            self.results.failure(name, "DB allowed knowledge_core as child")
        except Exception as e:
            if "knowledge_core" in str(e).lower() or "invariant" in str(e).lower():
                self.results.success(name)
            else:
                self.results.failure(name, f"Unexpected error: {e}")
    
    # =========================================================================
    # Main Runner
    # =========================================================================
    
    async def run_all(self):
        logger.info("=" * 60)
        logger.info("BACKEND VERIFICATION SUITE")
        logger.info("=" * 60)
        
        # Phase 1
        logger.info("\n--- Phase 1: Ingest Coverage ---")
        await self.test_ingest_youtube()
        await self.test_ingest_other_sources()
        
        # Phase 2
        logger.info("\n--- Phase 2: Generation Legality ---")
        await self.test_allowed_generations()
        await self.test_disallowed_generations()
        
        # Phase 3
        logger.info("\n--- Phase 3: Failure Atomicity ---")
        await self.test_missing_artifact_id()
        await self.test_invalid_target_type()
        
        # Phase 4
        logger.info("\n--- Phase 4: DAG Integrity ---")
        await self.test_knowledge_core_as_child_rejected()
        
        # Report
        return self.results.report()


async def main():
    verifier = BackendVerifier()
    success = await verifier.run_all()
    return 0 if success else 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
